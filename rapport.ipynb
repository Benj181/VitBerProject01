{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelling motor proteins with random walk in a ratchet potential switched on and of**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Excercise 1:** _The diffusion equation_\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **a)**\n",
    "\n",
    "We are given the function:\n",
    "\n",
    "$$\n",
    "\\phi(x,t) = \\frac{1}{\\sqrt{4\\pi D t}} \\int_{-\\infty}^{\\infty} h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\, dy.\n",
    "$$\n",
    "\n",
    "We want to show that it satisfies the diffusion equation:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = D \\frac{\\partial^2 \\phi}{\\partial x^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Step 1: Compute $ \\frac{\\partial \\phi}{\\partial t} $**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = \\frac{\\partial}{\\partial t} \\left[ \\frac{1}{\\sqrt{4\\pi D t}} \\int_{-\\infty}^{\\infty} dy \\, h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\right].\n",
    "$$\n",
    "\n",
    "Using the product rule we obtain\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = \\frac{\\partial}{\\partial t} \\left( \\frac{1}{\\sqrt{4\\pi D t}} \\right)  \\int_{-\\infty}^{\\infty} h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\, dy\n",
    "+ \\frac{1}{\\sqrt{4\\pi D t}} \\frac{\\partial}{\\partial t} \\left( \\int_{-\\infty}^{\\infty} h(y)  e^{-\\frac{(x-y)^2}{4Dt}} \\, dy \\right).\n",
    "$$\n",
    "Furthermore, applying the Lebniz integration rule:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = \\frac{\\partial}{\\partial t} \\left( \\frac{1}{\\sqrt{4\\pi D t}} \\right) \\int_{-\\infty}^{\\infty} h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\, dy\n",
    "+ \\frac{1}{\\sqrt{4\\pi D t}} \\int_{-\\infty}^{\\infty} h(y) \\frac{\\partial}{\\partial t} e^{-\\frac{(x-y)^2}{4Dt}} \\, dy.\n",
    "$$\n",
    "\n",
    "Differentiating the prefactor and the exponential term gives\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt} \\left( \\frac{1}{\\sqrt{4\\pi D t}} \\right) = -\\frac{1}{2} \\frac{1}{\\sqrt{4\\pi D t^3}}.\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial t} \\left( e^{-\\frac{(x-y)^2}{4Dt}}\\right) = e^{-\\frac{(x-y)^2}{4Dt}} \\cdot \\frac{(x-y)^2}{4D t^2}.\n",
    "$$\n",
    "Substituting back, we obtain\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = -\\frac{1}{2} \\frac{1}{\\sqrt{4\\pi D t^3}} \\int_{-\\infty}^{\\infty} dy \\, h(y) e^{-\\frac{(x-y)^2}{4Dt}} + \\frac{1}{\\sqrt{4\\pi D t}} \\int_{-\\infty}^{\\infty} dy \\, h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\cdot \\frac{(x-y)^2}{4D t^2}.\n",
    "$$\n",
    "Which simplifies to\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = \\frac{1}{\\sqrt{4\\pi D t}} \\int_{-\\infty}^{\\infty} h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\left( \\frac{(x-y)^2}{4D t^2} - \\frac{1}{2t} \\right) \\, dy.\n",
    "$$\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Compute $ \\frac{\\partial^2 \\phi}{\\partial x^2} $**\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial x} = \\frac{\\partial}{\\partial x} \\left[ \\frac{1}{\\sqrt{4\\pi D t}} \\int_{-\\infty}^{\\infty} dy \\, h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\right].\n",
    "$$\n",
    "\n",
    "Using the chain rule\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial x} = \\frac{1}{\\sqrt{4\\pi D t}} \\int_{-\\infty}^{\\infty} h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\left(-\\frac{x-y}{2Dt}\\right) \\, dy.\n",
    "$$\n",
    "\n",
    "Differentiating again\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 \\phi}{\\partial x^2} = \\frac{1}{\\sqrt{4\\pi D t}} \\int_{-\\infty}^{\\infty} h(y) e^{-\\frac{(x-y)^2}{4Dt}} \\left( \\frac{(x-y)^2}{4D^2 t^2} - \\frac{1}{2Dt} \\right) \\, dy.\n",
    "$$\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Verify the Diffusion Equation**\n",
    "\n",
    "Comparing the expressions for $ \\frac{\\partial \\phi}{\\partial t} $ and $ D \\frac{\\partial^2 \\phi}{\\partial x^2} $, we find that:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\phi}{\\partial t} = D \\frac{\\partial^2 \\phi}{\\partial x^2}.\n",
    "$$\n",
    "\n",
    "Thus, $ \\phi(x,t) $ satisfies the diffusion equation.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1b)**\n",
    "From the probability of finding a particle at a position $x$ in a potential landscape $V(x)$ as $$ P(x) = \\frac{e^{-\\beta V(x)}}{Z},$$ we are going to show how this results in the following probabilities for the particles movement:\n",
    "\n",
    "$$ p^+ = \\frac{1}{1 + e^{-\\beta [V(x_0-1) - V(x_0 + 1)]} + e^{-\\beta [V(x_0) - V(x_0+1)]}}$$\n",
    "$$p^0 = \\frac{1}{1 + e^{-\\beta [V(x_0-1) - V(x_0)]} + e^{-\\beta [V(x_0+1) - V(x_0)]}}$$\n",
    "$$p^- = \\frac{1}{1 + e^{-\\beta [V(x_0+1) - V(x_0-1)]} + e^{-\\beta [V(x_0) - V(x_0-1)]}}.$$\n",
    "\n",
    "By inserting the definition of the canonical partition function $Z$ with the energy being equal to the potential energy $V(x)$ at different positions, we obtain:\n",
    "\n",
    "\n",
    "$$ P(x) = \\frac{e^{-\\beta V(x)}}{Z} = \\frac{e^{-\\beta V(x)}}{e^{-\\beta V(x_0-1)} + e^{-\\beta V(x_0)} + e^{-\\beta V(x_0 +1)}}$$\n",
    "\n",
    "\n",
    "Since the probability of finding a particle at a position $x$ must be equal to the probability of the particle moving to $x$, we find the probability of the particle moving to $x_0 - 1$ as:\n",
    "\n",
    "\n",
    "$$ p^-  = P(x_0-1) = \\frac{e^{-\\beta V(x_0-1)}}{e^{-\\beta V(x_0-1)} + e^{-\\beta V(x_0)} + e^{-\\beta V(x_0 +1)}}.$$ \n",
    "\n",
    "Doing the algebra and simplifying gives\n",
    "\n",
    "$$ p^- = \\frac{1}{1 + e^{-\\beta [V(x_0+1) - V(x_0-1)]} + e^{-\\beta [V(x_0) - V(x_0-1)]}}.$$\n",
    "\n",
    "\n",
    "By repeating this process for the remaining steps $x_0$ and $x_0 + 1$, we obtain:\n",
    "\n",
    "\n",
    "$$p^0 = P(X_0) = \\frac{1}{1 + e^{-\\beta [V(x_0-1) - V(x_0)]} + e^{-\\beta [V(x_0+1) - V(x_0)]}}$$\n",
    "\n",
    "$$p^+ = P(X_0+1) = \\frac{1}{1 + e^{-\\beta [V(x_0-1) - V(x_0 + 1)]} + e^{-\\beta [V(x_0) - V(x_0+1)]}} \\quad \\blacksquare.$$  \n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1c)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First case: $k_B T$ $\\gg$ $\\lvert V(x+1) - V(x) \\rvert$\n",
    "\n",
    "One can see that for the boundary condition when $k_B T$ $\\gg$ $\\lvert V(x+1) - V(x) \\rvert$, each exponential term in the denominator in the three probablities {${p^+, p^0, p^-}$} goes to 1. \n",
    "\n",
    "- For $p^+$, we notice that the third term in the denominator describes the potential difference between two adjacent poential steps. Given the boundary condition, this potential difference is significantly smaller than $k_B T$. This yields an expression $e$ to the power of 0, making the exponential term go towards 1. For the second term, we notice that this describes the potential difference between $x_0-1$ and $x_0+1$, giving us the expression $\\frac {2 \\lvert V(x+1) - V(x) \\rvert} {k_B T}$ in the exponent, which will also have the term go towards 1. Resulting in the probablitiy $p^+$ going towards $\\frac 1 3$.\n",
    "\n",
    "- For $p^0$, we notice that both the exponential terms describe a potential step from $x_0$ to $±1$. Similarly for the case of $p^+$, these terms are significantly smaller than $k_B T$, making each term go towards 1, ultimately letting the probability $p^0$ go towards $\\frac 1 3$\n",
    "\n",
    "- For $p^-$, we use the same arguments as for $p^+$. The exponents in both the exponential terms are both significantly smaller than $k_B T$, which yields a $e$ to the power of 0, also giving a probability of $\\frac 1 3$.\n",
    "\n",
    "As a final remark, one may notice that the sum of each probability {${p^+, p^0, p^-}$} sums up to 1, following the law of conservation of probability.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Second case: $k_B T$ $\\ll$ $\\lvert V(x+1) - V(x) \\rvert$**\n",
    "\n",
    "For the case where $k_B T$ $\\ll$ $\\lvert V(x+1) - V(x) \\rvert$, we will see that one of the expressions will go to 1, while the other two expressions will die out and go towards 0. We consider $V(x_0-1)$, $V(x_0)$, and $V(x_0+1)$ to be respective potential steps, and will assume that $V(x_0-1)$ $\\ll$ $V(x_0)$ $\\ll$ and $V(x_0+1)$. Using this, we may examine each of the exponential terms in the three expressions:\n",
    "- For $p^+$, we notice that $V(x_0-1)-V(x_0+1)$ will yield a negative number. Using the given boundary condition, we are now considering a negative number divided by $\\beta$, a significantly smaller number. The whole term will then yield $e$ to the power of a large positive number, resulting in the term exploding towards infinity. For $V(x_0)-V(x_0+1)$, we notice that this will produce a negative number similar to the former term. However, due to the explosive growth of the exponential function, this term will be negligible. At last, the boundary condition will have $å^+$ go towards 0\n",
    "\n",
    "- For $p^0$, following the same steps as above, we notice that the denominator will quickly explode to infinity, yielding a propability of 0.\n",
    "\n",
    "- For $p^-$, we now notice that both the exponential terms, $V(x_0+1)-V(x_0-1)$ and $V(x_0)-V(x_0-1)$, have exponents yielding a positive number. This will result in both terms being raised to the power of negative infinity, making them decay quickly. This will result in $p^-$ going towards 1.\n",
    "\n",
    "Similarly to the first case, the probability is conserved.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simplifying the random walk using an energy scale argument**\n",
    "Using an energy scale argument, we consider the two extremes described in the two boundary conditions. In one extreme, the temperature is significantly larger than the energy potentials and as discussed above, this results in the energy potential being negligible to the probability. In the second extreme case the temperature is significantly smaller than the potentials. As a result, the energy potential plays the dominating role for the probabability. This is assuming that the potential energy grows monotonously as $x$ goes from smaller to bigger values of $x$. However, this might not always be the case. The potential might decrease monotonously, and it might oscillate. This will however not change the proposed argument. For higher temperatures, the potential will still be negligible, while lower temperatures will have probabilities dependant on the potential differences. \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Excercise 2:** _Random walk in a potential_\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task we are going to plot the distrubution of the particles after random walking. The first part of this task contains the main code. All the partial assignments will send values to this main code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTING LIBRARIES\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, potentialFunction, betak):\n",
    "        self.x = 0\n",
    "        self.V = potentialFunction\n",
    "        self.betak = betak\n",
    "\n",
    "    def pPlus(self):\n",
    "        return 1 / (1 + np.exp(-self.betak * (self.V(self.x - 1) - self.V(self.x + 1))) \n",
    "                    + np.exp(-self.betak * (self.V(self.x) - self.V(self.x + 1))))\n",
    "    \n",
    "    def pMinus(self):\n",
    "        return 1 / (1 + np.exp(-self.betak * (self.V(self.x + 1) - self.V(self.x - 1))) \n",
    "                    + np.exp(-self.betak * (self.V(self.x) - self.V(self.x - 1))))\n",
    "\n",
    "\n",
    "    def walkStep(self):\n",
    "        prob = random.uniform(0, 1)\n",
    "        if prob <= self.pMinus():\n",
    "            self.x -= 1\n",
    "        if prob > 1 - self.pPlus():\n",
    "            self.x += 1\n",
    "        else:\n",
    "            self.x = self.x\n",
    "    \n",
    "    def getPos(self):\n",
    "        return self.x\n",
    "    \n",
    "    def getProb(self):\n",
    "        return float(self.pMinus()), float(1 - (self.pPlus() + self.pMinus())), float(self.pPlus())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HOVEDFUNKSJONEN SOM UTFØRER BEREGNINGENE\n",
    "\n",
    "def calculation(V, name):\n",
    "    betakList = [0.01, 1, 100]\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    for i, betak in enumerate(betakList):\n",
    "        Particles = [Particle(V, betak) for _ in range(numberOfParticles)]\n",
    "        for j, _ in enumerate(range(numberOfSteps)):\n",
    "            print(f'Step: {j} with beta*k = {betak}')\n",
    "            for particle in Particles:\n",
    "                particle.walkStep()\n",
    "\n",
    "        positions = np.array([particle.getPos() for particle in Particles])\n",
    "        mu, sigma = stats.norm.fit(positions)\n",
    "        x = np.linspace(min(positions), max(positions), 1000)\n",
    "        pdf = stats.norm.pdf(x, mu, sigma)\n",
    "        ax[i].plot(x, pdf, 'r-', label=f\"μ={mu:.2f}, σ={sigma:.2f}, βk {betak}\")\n",
    "        ax[i].hist(positions, bins=20, density=True, alpha=0.6, color='g')\n",
    "        ax[i].set_title(f\"βk = {betak}\")\n",
    "        ax[i].set_xlabel(\"Position\")\n",
    "        ax[i].set_ylabel(\"Probability density\")\n",
    "        ax[i].legend()\n",
    "\n",
    "    fig.suptitle(f\"Particle distribution with potetial {name}\")\n",
    "    plt.show()\n",
    "\n",
    "# numberOfParticles = 10_000\n",
    "# numberOfSteps = 200\n",
    "numberOfParticles = 1_000 \n",
    "numberOfSteps = 200\n",
    "\n",
    "V = {'k' : lambda x: 1,\n",
    "     '-k*x' : lambda x: -x, \n",
    "     'k(x/15 - np.cos(x/3))' : lambda x: x/15 - np.cos(x/3), \n",
    "     'k*x**4' : lambda x: x**4}\n",
    "\n",
    "# calculation(V['k'], \"k\")\n",
    "# calculation(V['-k*x'], \"-k*x\")\n",
    "# calculation(V['k(x/15 - np.cos(x/3))'], 'k(x/15 - np.cos(x/3))')\n",
    "# calculation(V['k*x**4'], 'k*x**4')\n",
    "\n",
    "# test = Particle(V['-k*x'], 1)\n",
    "# for _ in range(10):\n",
    "#     test.walkStep()\n",
    "#     print(f\"pos: {test.getPos()} prob(-,0,+):{test.getProb()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculation(V['k'], \"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculation(V['-k*x'], \"-k*x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculation(V['k(x/15 - np.cos(x/3))'], 'k(x/15 - np.cos(x/3))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculation(V['k*x**4'], 'k*x**4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Excercise 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Excercise4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
